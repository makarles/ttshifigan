## Реализация вокодера HiFi-GAN для синтеза речи

Датасет: [RUSLAN](https://ruslan-corpus.github.io/) (22.05 kHz) 

Автор: Макар Лесниченко

------------------------------------------------------------------------

# 1. Введение

В рамках данной работы была реализована и обучена нейросетевая модель
вокодера на основе архитектуры HiFi-GAN для генерации речевого сигнала
из мел-спектрограмм.

Основная цель проекта — построить:

-   стабильный GAN-вокодер,
-   воспроизводимый пайплайн обучения,
-   корректный режим resynthesis (Audio → Mel → Vocoder → Audio),
-   демонстрационный ноутбук для Google Colab,
-   систему логирования обучения.

Проект полностью реализован с нуля без использования предобученных
вокодеров.

Для быстрого ознакомления рекомендуется запустить [demo-ноутбук](https://colab.research.google.com/github/makarles/ttshifigan/blob/main/demo.ipynb)

------------------------------------------------------------------------


# 2. Используемые данные

Обучение проводилось на датасете RUSLAN.

-   Исходная частота записи: 44100 Hz
-   В работе использована частота: 22050 Hz (с ресемплированием)
-   Формат признаков: 80-мерные мел-спектрограммы

Для демонстрации в репозитории используются:

-   [ruslan_50](https://drive.google.com/drive/folders/1sKwsSfRuW4ZsgIbnoG90uBPWz16s48Hh?usp=drive_link) — подмножество из 50 аудиофайлов
-   [mos_gt](https://drive.google.com/drive/folders/1KrDyNdbGdOz32gmIrbFrV2RstpFxoQwe?usp=sharing) — 3 аудиофайла для MOS-оценки

Демо-данные автоматически скачиваются через demo.ipynb.

------------------------------------------------------------------------

# 3. Архитектура модели

Использована архитектура HiFi-GAN (V2):

-   Generator с residual блоками
-   Multi-Period Discriminator (MPD)
-   Multi-Scale Discriminator (MSD)
-   Mel-spectrogram L1 loss
-   Feature Matching Loss
-   Adversarial Loss

Формирование mel-спектрограмм:

-   n_fft = 1024
-   hop_length = 256
-   win_length = 1024
-   n_mels = 80
-   f_min = 0
-   f_max = 11025

------------------------------------------------------------------------

# 4. Стратегия обучения

Обучение проводилось на RTX 4070 (12GB) в две фазы с целью повысить стабильность и качество GAN.

------------------------------------------------------------------------

# 4.1 Фаза 1 — Базовое обучение

Цель: - стабилизация GAN - обучение грубой структуры сигнала

Параметры фазы 1

| Параметр       | Значение      |
|----------------|---------------|
| sample_rate    | 22050         |
| segment_size   | 16384         |
| batch_size     | 8             |
| learning_rate  | 5e-5          |
| betas          | (0.8, 0.99)   |
| weight_decay   | 0.0           |
| max_steps      | 120000        |

На этом этапе модель достигла устойчивой сходимости.

------------------------------------------------------------------------

# 4.2 Фаза 2 — Fine-Tuning

Цель: - улучшение высокочастотных компонент - снижение шумов - повышение
спектральной детализации

Фаза 2 запускалась с чекпойнта фазы 1.

Параметры фазы 2

| Параметр               | Значение      |
|------------------------|---------------|
| sample_rate            | 22050         |
| segment_size           | 16384         |
| batch_size             | 8             |
| learning_rate          | 2e-5          |
| betas                  | (0.8, 0.99)   |
| weight_decay           | 0.0           |
| max_steps              | 180000        |

Понижение learning rate позволило более аккуратно донастроить генератор
без разрушения уже выученной структуры сигнала.

------------------------------------------------------------------------

# 5. Логирование (Weights & Biases)

Для логирования использовался Weights & Biases в offline-режиме.

Во время синхронизации возникла ошибка авторизации (HTTP 403), из-за
чего (скорее всего, из-за блокировки сервиса в России...) история метрик (history) не была загружена в облако.
Прошу прощения.

Это не повлияло на обучение, но ограничило визуализацию динамики лоссов.
Логи сохранились на локальном ПК, на котором проводилось обучение модели.

Метрики первой фазы обучения:

`{"_runtime": 38844.9314274, "loss/d_total": 1.7608157396316528, "loss/mel": 8.581755638122559, "steps_per_sec": 3.089612230445129, "loss/g_total": 406.29290771484375, "eta_hours": 8.990700355227347e-05, "step": 119999, "_timestamp": 1771494926.014291, "_step": 119999}`

Метрики второй фазы обучения:

`{"_runtime": 18744.250003, "_step": 179999, "loss/g_total": 368.23248291015625, "loss/mel": 7.699151039123535, "steps_per_sec": 3.202594211752543, "loss/d_total": 1.6284438371658325, "eta_hours": 8.673524006207784e-05, "step": 179999, "_timestamp": 1771517567.2534838}`

------------------------------------------------------------------------

# 6. Анализ качества на обучающих данных (RUSLAN)

В эксперименте были выбраны 50 аудиофайлов из тестовой части датасета
RUSLAN.
Для каждого файла:

-   извлечена мел-спектрограмма,
-   выполнена генерация сигнала вокодером (режим resynthesize),
-   построены графики waveform и STFT для оригинального и
    синтезированного сигналов.

# Наблюдения

Во временной области (waveform):

-   Форма сигнала в целом совпадает по амплитуде и общей структуре.
-   Наблюдается небольшое сглаживание амплитудных пиков.
-   Отсутствуют резкие выбросы или нестабильность сигнала.
-   Сохраняется корректная временная динамика речи.

В частотно-временной области (STFT):

-   Общая гармоническая структура сигнала сохраняется.
-   Форманты воспроизводятся корректно.
-   Высокочастотная энергия несколько снижена.
-   Наблюдается сглаживание тонких спектральных деталей.

Субъективное восприятие:

-   Речь разборчива и понятна.
-   Слышна лёгкая синтетичность звучания.
-   При внимательном прослушивании можно отличить синтез от оригинала.


Вокодер корректно воспроизводит речь обучающего домена, демонстрируя
хорошее совпадение во временной и спектральной областях.
Однако наблюдается частичная потеря высокочастотной детализации и
незначительная синтетичность звучания.

------------------------------------------------------------------------

# 7. Анализ на внешних данных (MOS)

Для анализа использовались 3 тестовых предложения из раздела MOS.

Для каждого аудиофайла:

-   извлечена мел-спектрограмма,
-   выполнена генерация сигнала вокодером,
-   построены waveform и STFT сравнения.

# Наблюдения

-   Амплитудная структура сигнала в целом совпадает с оригиналом.
-   В спектрограмме заметно более выраженное сглаживание высокочастотных
    компонент.
-   Гармоническая структура сохраняется, однако детализация ниже, чем на
    обучающих данных.
-   Субъективно синтетичность выражена сильнее по сравнению с RUSLAN.

Сравнение с обучающими данными:

-   На обучающих данных качество генерации выше.
-   На внешних данных артефакты выражены сильнее.
-   Различия заметны как в спектральной области, так и при
    прослушивании.

Возможные причины различий:

-   Domain shift (отличие распределения данных).
-   Отличия дикции и акустических характеристик речи.
-   Различия спектрального распределения энергии.
-   Ограниченная обобщающая способность модели.


------------------------------------------------------------------------

# 8. Скорость инференса

Измеренный Real-Time Factor:

RTF ≈ 0.06

Это означает, что модель работает примерно в 16 раз быстрее реального
времени на GPU.

------------------------------------------------------------------------

# 9. Графики

Сравнение waveform и STFT представлено в директориях:

-    `ttshifigan/report_figs/`
-    `ttshifigan/report_figs_mos/`

Графики демонстрируют относительно (с учетом специфики обучения сети) хорошее совпадение спектральной структуры с
референсом.

------------------------------------------------------------------------

# 10. Установка

   ```bash
   git clone https://github.com/makarles/ttshifigan.git
   cd ttshifigan
   pip install -r requirements.txt
   ```

------------------------------------------------------------------------

# 11. Чекпойнт

Файл last.pt (~800 MB) размещён на [Google Drive](https://drive.google.com/file/d/1HZ-NSQ0c3f_ZUhCibULGdMXGn2HHcbzC/view?usp=sharing).



После скачивания необходимо поместить его в:

    checkpoints/last.pt

------------------------------------------------------------------------

# 12. Demo (Google Colab)

Файл [demo.ipynb](https://colab.research.google.com/github/makarles/ttshifigan/blob/main/demo.ipynb):

-   клонирует репозиторий
-   устанавливает зависимости
-   скачивает веса
-   скачивает demo-данные
-   запускает resynthesis
-   генерирует MOS-примеры
-   измеряет скорость инференса


------------------------------------------------------------------------

# 13. Заключение

Вокодер HiFi-GAN успешно обучен на датасете RUSLAN и протестирован на датасете MOS.

Модель: 
- стабильно работает
- генерирует разборчивую речь
- демонстрирует высокую скорость инференса
- воспроизводима через demo-ноутбук.


